{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "087e073f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import preprocessing \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1214b852",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('banktransaction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a74ed4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "typeoferror=data['typeoffraud']\n",
    "data.drop(['typeoffraud'],axis=1,inplace=True)\n",
    "data.drop(['date'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb53aae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = preprocessing.LabelEncoder() \n",
    "\n",
    "data['typeofaction']= label_encoder.fit_transform(data['typeofaction']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a445539",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data\n",
    "y=data['isfraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44db4ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Specs          Score\n",
      "3  amountofmoney  296031.222043\n",
      "2  destinationid  265713.164204\n",
      "1       sourceid   31801.039523\n",
      "4        isfraud     941.000000\n",
      "0   typeofaction       2.591578\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "bestfeatures = SelectKBest(score_func=chi2, k=4)\n",
    "fit = bestfeatures.fit(X,y)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X.columns)\n",
    "#concat two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n",
    "print(featureScores.nlargest(10,'Score'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f45b7882",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93a06aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "        X, y\n",
    "        , test_size=.2, random_state=42)\n",
    "train_fraud_count = x_train['isfraud'].value_counts()\n",
    "    \n",
    "test_fraud_count = x_test['isfraud'].value_counts()\n",
    "trl0=list()\n",
    "trl1=list()\n",
    "te1=list()\n",
    "te0=list()\n",
    "\n",
    "tr1=train_fraud_count[1]/(train_fraud_count[0]+train_fraud_count[1])\n",
    "tr0=train_fraud_count[0]/(train_fraud_count[0]+train_fraud_count[1])\n",
    "te1=test_fraud_count[1]/(test_fraud_count[0]+test_fraud_count[1])\n",
    "te0=test_fraud_count[0]/(test_fraud_count[0]+test_fraud_count[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "071c9a3f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_MissingValues' from 'sklearn.utils._param_validation' (/Users/yogeshthangamuthu/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m x_train, x_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[1;32m      2\u001b[0m         X, y\n\u001b[1;32m      3\u001b[0m         , test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomOverSampler\n\u001b[1;32m      6\u001b[0m method \u001b[38;5;241m=\u001b[39m RandomOverSampler(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      7\u001b[0m X_rtrain, y_rtrain \u001b[38;5;241m=\u001b[39m  method\u001b[38;5;241m.\u001b[39mfit_resample(x_train, y_train)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/imblearn/__init__.py:52\u001b[0m\n\u001b[1;32m     48\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPartial import of imblearn during the build process.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;66;03m# We are not importing the rest of scikit-learn during the build\u001b[39;00m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;66;03m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     53\u001b[0m         combine,\n\u001b[1;32m     54\u001b[0m         ensemble,\n\u001b[1;32m     55\u001b[0m         exceptions,\n\u001b[1;32m     56\u001b[0m         metrics,\n\u001b[1;32m     57\u001b[0m         over_sampling,\n\u001b[1;32m     58\u001b[0m         pipeline,\n\u001b[1;32m     59\u001b[0m         tensorflow,\n\u001b[1;32m     60\u001b[0m         under_sampling,\n\u001b[1;32m     61\u001b[0m         utils,\n\u001b[1;32m     62\u001b[0m     )\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_version\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FunctionSampler\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/imblearn/combine/__init__.py:5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"The :mod:`imblearn.combine` provides methods which combine\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mover-sampling and under-sampling.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smote_enn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTEENN\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smote_tomek\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTETomek\n\u001b[1;32m      8\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTEENN\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTETomek\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/imblearn/combine/_smote_enn.py:12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_X_y\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseSampler\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseOverSampler\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/imblearn/base.py:21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmulticlass\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_classification_targets\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_sampling_strategy, check_target_type\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m validate_parameter_constraints\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ArraysTransformer\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mSamplerMixin\u001b[39;00m(BaseEstimator, metaclass\u001b[38;5;241m=\u001b[39mABCMeta):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/imblearn/utils/_param_validation.py:908\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generate_valid_param  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m    907\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m validate_parameter_constraints  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m--> 908\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    909\u001b[0m     HasMethods,\n\u001b[1;32m    910\u001b[0m     Hidden,\n\u001b[1;32m    911\u001b[0m     Interval,\n\u001b[1;32m    912\u001b[0m     Options,\n\u001b[1;32m    913\u001b[0m     StrOptions,\n\u001b[1;32m    914\u001b[0m     _ArrayLikes,\n\u001b[1;32m    915\u001b[0m     _Booleans,\n\u001b[1;32m    916\u001b[0m     _Callables,\n\u001b[1;32m    917\u001b[0m     _CVObjects,\n\u001b[1;32m    918\u001b[0m     _InstancesOf,\n\u001b[1;32m    919\u001b[0m     _IterablesNotString,\n\u001b[1;32m    920\u001b[0m     _MissingValues,\n\u001b[1;32m    921\u001b[0m     _NoneConstraint,\n\u001b[1;32m    922\u001b[0m     _PandasNAConstraint,\n\u001b[1;32m    923\u001b[0m     _RandomStates,\n\u001b[1;32m    924\u001b[0m     _SparseMatrices,\n\u001b[1;32m    925\u001b[0m     _VerboseHelper,\n\u001b[1;32m    926\u001b[0m     make_constraint,\n\u001b[1;32m    927\u001b[0m     validate_params,\n\u001b[1;32m    928\u001b[0m )\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name '_MissingValues' from 'sklearn.utils._param_validation' (/Users/yogeshthangamuthu/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py)"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "        X, y\n",
    "        , test_size=.2, random_state=42)\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "method = RandomOverSampler(random_state=42)\n",
    "X_rtrain, y_rtrain =  method.fit_resample(x_train, y_train)\n",
    "\n",
    "X_rtrain, y_rtrain\n",
    "train_fraud_count = X_rtrain['isfraud'].value_counts()\n",
    "    \n",
    "\n",
    "trl0=list()\n",
    "trl1=list()\n",
    "\n",
    "tr1=train_fraud_count[1]/(train_fraud_count[0]+train_fraud_count[1])\n",
    "tr0=train_fraud_count[0]/(train_fraud_count[0]+train_fraud_count[1])\n",
    "\n",
    "tr1,tr0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da94fc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=0).fit(X_rtrain, y_rtrain)\n",
    "clf_pred=clf.predict(x_test)\n",
    "clf_score = accuracy_score(clf_pred, y_test)\n",
    "auc = metrics.roc_auc_score(y_test, clf_pred)\n",
    "print(auc)\n",
    "print(clf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1496f23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf1.fit(X_rtrain, y_rtrain)\n",
    "clf_pred=clf1.predict(x_test)\n",
    "clf_score = accuracy_score(clf_pred, y_test)\n",
    "auc = metrics.roc_auc_score(y_test, clf_pred)\n",
    "print(auc)\n",
    "print(clf_score)\n",
    "cm = confusion_matrix(y_test, clf_pred)\n",
    "a=cm[[0][0]]\n",
    "b=cm[[1][0]]\n",
    "print(a[0]/(a[0]+b[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf34e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf2.fit(x_train, y_train)\n",
    "clf_pred=clf2.predict(x_test)\n",
    "clf_score = accuracy_score(clf_pred, y_test)\n",
    "auc = metrics.roc_auc_score(y_test, clf_pred)\n",
    "print(auc)\n",
    "print(clf_score)\n",
    "cm = confusion_matrix(y_test, clf_pred)\n",
    "a=cm[[0][0]]\n",
    "b=cm[[1][0]]\n",
    "print(a[0]/(a[0]+b[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7167c9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "xgb_model = XGBClassifier().fit(X_rtrain, y_rtrain)\n",
    "\n",
    "# predict\n",
    "xgb_y_predict = xgb_model.predict(x_test)\n",
    "\n",
    "# accuracy score\n",
    "xgb_score = accuracy_score(xgb_y_predict, y_test)\n",
    "auc = metrics.roc_auc_score(y_test, xgb_y_predict)\n",
    "print(auc)\n",
    "print(xgb_score)\n",
    "from sklearn.metrics import confusion_matrix  \n",
    "cm = confusion_matrix(y_test, xgb_y_predict)\n",
    "a=cm[[0][0]]\n",
    "b=cm[[1][0]]\n",
    "print(a[0]/(a[0]+b[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9afb7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [('LogReg', LogisticRegression()), \n",
    "          ('SVM', SVC()), \n",
    "          ('DecTree', DecisionTreeClassifier()),\n",
    "          ('KNN', KNeighborsClassifier()),\n",
    "          ('LinDisc', LinearDiscriminantAnalysis()),\n",
    "          ('GaussianNB', GaussianNB())]\n",
    "outcome=list()\n",
    "model_names=list()\n",
    "for model_name, model in models:\n",
    "    model_name = model.fit(x_train, y_train)\n",
    "    model_name_pred=model_name.predict(x_test)\n",
    "    model_name_score = accuracy_score(model_name_pred, y_test)\n",
    "    auc = metrics.roc_auc_score(y_test, model_name_pred)\n",
    "    print(model_name)\n",
    "    print(auc)\n",
    "    print(model_name_score)\n",
    "    cm = confusion_matrix(y_test, model_name_pred)\n",
    "    a=cm[[0][0]]\n",
    "    b=cm[[1][0]]\n",
    "    print(a[0]/(a[0]+b[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50ad66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [('LogReg', LogisticRegression()), \n",
    "          ('SVM', SVC()), \n",
    "          ('DecTree', DecisionTreeClassifier()),\n",
    "          ('KNN', KNeighborsClassifier()),\n",
    "          ('LinDisc', LinearDiscriminantAnalysis()),\n",
    "          ('GaussianNB', GaussianNB())]\n",
    "outcome=list()\n",
    "model_names=list()\n",
    "for model_name, model in models:\n",
    "    model_name = model.fit(X_rtrain, y_rtrain)\n",
    "    model_name_pred=model_name.predict(x_test)\n",
    "    model_name_score = accuracy_score(model_name_pred, y_test)\n",
    "    auc = metrics.roc_auc_score(y_test, model_name_pred)\n",
    "    print(model_name)\n",
    "    print(auc)\n",
    "    print(model_name_score)\n",
    "    cm = confusion_matrix(y_test, model_name_pred)\n",
    "    a=cm[[0][0]]\n",
    "    b=cm[[1][0]]\n",
    "    print(a[0]/(a[0]+b[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a599a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        X, y\n",
    "        , test_size=0.20, random_state=42)\n",
    "    train_fraud_count = x_train['isfraud'].value_counts()\n",
    "    test_fraud_count = x_test['isfraud'].value_counts()\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f088ee3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9068de12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
